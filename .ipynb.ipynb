{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4217c3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ArticleId</th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>893</td>\n",
       "      <td>rangers seal old firm win goals from gregory v...</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1164</td>\n",
       "      <td>bt program to beat dialler scams bt is introdu...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1696</td>\n",
       "      <td>new  yob  targets to be unveiled fifty new are...</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>396</td>\n",
       "      <td>holmes is hit by hamstring injury kelly holmes...</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1862</td>\n",
       "      <td>capriati out of australian open jennifer capri...</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ArticleId                                               Text  Category\n",
       "0        893  rangers seal old firm win goals from gregory v...     sport\n",
       "1       1164  bt program to beat dialler scams bt is introdu...      tech\n",
       "2       1696  new  yob  targets to be unveiled fifty new are...  politics\n",
       "3        396  holmes is hit by hamstring injury kelly holmes...     sport\n",
       "4       1862  capriati out of australian open jennifer capri...     sport"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(r\"C:\\Users\\jappaka\\Desktop\\python\\news-train-1.csv\")\n",
    "\n",
    "# Taking first rows of the dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0fe6e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\jappaka\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jappaka\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ArticleId</th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "      <th>Unigrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>893</td>\n",
       "      <td>rangers seal old firm win goals from gregory v...</td>\n",
       "      <td>sport</td>\n",
       "      <td>[ranger, seal, old, firm, win, goal, gregori, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1164</td>\n",
       "      <td>bt program to beat dialler scams bt is introdu...</td>\n",
       "      <td>tech</td>\n",
       "      <td>[bt, program, beat, dialler, scam, bt, introdu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1696</td>\n",
       "      <td>new  yob  targets to be unveiled fifty new are...</td>\n",
       "      <td>politics</td>\n",
       "      <td>[new, yob, target, unveil, fifti, new, area, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>396</td>\n",
       "      <td>holmes is hit by hamstring injury kelly holmes...</td>\n",
       "      <td>sport</td>\n",
       "      <td>[holm, hit, hamstr, injuri, kelli, holm, forc,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1862</td>\n",
       "      <td>capriati out of australian open jennifer capri...</td>\n",
       "      <td>sport</td>\n",
       "      <td>[capriati, australian, open, jennif, capriati,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ArticleId                                               Text  Category  \\\n",
       "0        893  rangers seal old firm win goals from gregory v...     sport   \n",
       "1       1164  bt program to beat dialler scams bt is introdu...      tech   \n",
       "2       1696  new  yob  targets to be unveiled fifty new are...  politics   \n",
       "3        396  holmes is hit by hamstring injury kelly holmes...     sport   \n",
       "4       1862  capriati out of australian open jennifer capri...     sport   \n",
       "\n",
       "                                            Unigrams  \n",
       "0  [ranger, seal, old, firm, win, goal, gregori, ...  \n",
       "1  [bt, program, beat, dialler, scam, bt, introdu...  \n",
       "2  [new, yob, target, unveil, fifti, new, area, g...  \n",
       "3  [holm, hit, hamstr, injuri, kelli, holm, forc,...  \n",
       "4  [capriati, australian, open, jennif, capriati,...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding get_tokens method file\n",
    "import string\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import *\n",
    "\n",
    "\n",
    "\n",
    "# stemming tool from nltk\n",
    "stemmer = PorterStemmer()\n",
    "# a mapping dictionary to remove punctuations\n",
    "remove_punctuation_map = dict((ord(char), None) for char in string.punctuation)\n",
    "\n",
    "def get_tokens(text):\n",
    "    # turn document into lowercase\n",
    "    lowers = text.lower()\n",
    "    # remove punctuations\n",
    "    no_punctuation = lowers.translate(remove_punctuation_map)\n",
    "    # tokenize document\n",
    "    tokens = nltk.word_tokenize(no_punctuation)\n",
    "    # remove stop words\n",
    "    filtered = [w for w in tokens if not w in stopwords.words('english')]\n",
    "    # stemming process\n",
    "    stemmed = [stemmer.stem(item) for item in filtered]\n",
    "    # final unigrams\n",
    "    return stemmed\n",
    "\n",
    "# Applying the function to the 'Text' column\n",
    "data[\"Unigrams\"] = data[\"Text\"].apply(get_tokens)\n",
    "\n",
    "# First rows with the \"Unigrams\" column\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52888bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(r\"data_pickle.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca9c8d16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ArticleId</th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "      <th>Unigrams</th>\n",
       "      <th>Filtered_Unigrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>893</td>\n",
       "      <td>rangers seal old firm win goals from gregory v...</td>\n",
       "      <td>sport</td>\n",
       "      <td>[ranger, seal, old, firm, win, goal, gregori, ...</td>\n",
       "      <td>[old, firm, win, goal, gave, victori, park, mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1164</td>\n",
       "      <td>bt program to beat dialler scams bt is introdu...</td>\n",
       "      <td>tech</td>\n",
       "      <td>[bt, program, beat, dialler, scam, bt, introdu...</td>\n",
       "      <td>[bt, program, beat, bt, introduc, two, initi, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1696</td>\n",
       "      <td>new  yob  targets to be unveiled fifty new are...</td>\n",
       "      <td>politics</td>\n",
       "      <td>[new, yob, target, unveil, fifti, new, area, g...</td>\n",
       "      <td>[new, target, unveil, new, area, get, special,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>396</td>\n",
       "      <td>holmes is hit by hamstring injury kelly holmes...</td>\n",
       "      <td>sport</td>\n",
       "      <td>[holm, hit, hamstr, injuri, kelli, holm, forc,...</td>\n",
       "      <td>[hit, injuri, forc, weekend, european, athlet,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1862</td>\n",
       "      <td>capriati out of australian open jennifer capri...</td>\n",
       "      <td>sport</td>\n",
       "      <td>[capriati, australian, open, jennif, capriati,...</td>\n",
       "      <td>[australian, open, becom, third, lead, austral...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ArticleId                                               Text  Category  \\\n",
       "0        893  rangers seal old firm win goals from gregory v...     sport   \n",
       "1       1164  bt program to beat dialler scams bt is introdu...      tech   \n",
       "2       1696  new  yob  targets to be unveiled fifty new are...  politics   \n",
       "3        396  holmes is hit by hamstring injury kelly holmes...     sport   \n",
       "4       1862  capriati out of australian open jennifer capri...     sport   \n",
       "\n",
       "                                            Unigrams  \\\n",
       "0  [ranger, seal, old, firm, win, goal, gregori, ...   \n",
       "1  [bt, program, beat, dialler, scam, bt, introdu...   \n",
       "2  [new, yob, target, unveil, fifti, new, area, g...   \n",
       "3  [holm, hit, hamstr, injuri, kelli, holm, forc,...   \n",
       "4  [capriati, australian, open, jennif, capriati,...   \n",
       "\n",
       "                                   Filtered_Unigrams  \n",
       "0  [old, firm, win, goal, gave, victori, park, mo...  \n",
       "1  [bt, program, beat, bt, introduc, two, initi, ...  \n",
       "2  [new, target, unveil, new, area, get, special,...  \n",
       "3  [hit, injuri, forc, weekend, european, athlet,...  \n",
       "4  [australian, open, becom, third, lead, austral...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the dictionary file\n",
    "with open(r\"C:\\Users\\jappaka\\Desktop\\python\\dictionary.txt\", \"r\") as file:\n",
    "    dictionary_words = set(file.read().splitlines())\n",
    "\n",
    "# Filtering the unigrams based on the dictionary\n",
    "data[\"Filtered_Unigrams\"] = data[\"Unigrams\"].apply(lambda unigrams: [word for word in unigrams if word in dictionary_words])\n",
    "\n",
    "# Displaying the first few rows with the new \"Filtered_Unigrams\" column\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97381afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.36427118 ... 0.         0.         0.        ]\n",
      " [0.36385541 0.32813062 0.         ... 0.         0.         0.        ]\n",
      " [0.24257027 0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Load the dictionary content from the 'dictionary.txt' file\n",
    "with open('C:\\\\Users\\\\jappaka\\\\Desktop\\\\python\\\\dictionary.txt', 'r') as file:\n",
    "    dictionary_content = file.readlines()\n",
    "    \n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from math import log\n",
    "\n",
    "# Assuming your dataset is loaded as 'data' with the 'Filtered_Unigrams' column already populated.\n",
    "# Make sure to preprocess your data to have the 'Filtered_Unigrams' column as we did earlier.\n",
    "\n",
    "# Number of documents\n",
    "n = len(data)\n",
    "\n",
    "# List of words from dictionary.txt\n",
    "dictionary_list = [word.strip() for word in dictionary_content]\n",
    "\n",
    "# Pre-computing the IDF for each word across all documents\n",
    "idf_values = {}\n",
    "for word in dictionary_list:\n",
    "    # Count of documents where the word appears\n",
    "    mj = sum([1 for unigram_list in data[\"Filtered_Unigrams\"] if word in unigram_list])\n",
    "    idf_values[word] = log(n / mj)\n",
    "\n",
    "# Computing the TFIDF matrix iteratively\n",
    "tfidf_matrix_optimized = np.zeros((n, len(dictionary_list)))\n",
    "\n",
    "for i, unigrams in enumerate(data[\"Filtered_Unigrams\"]):\n",
    "    word_counts = Counter(unigrams)\n",
    "    for j, word in enumerate(dictionary_list):\n",
    "        # TF calculation\n",
    "        tf = word_counts[word] / max(word_counts.values()) if word in word_counts else 0\n",
    "        # TFIDF calculation\n",
    "        tfidf_matrix_optimized[i][j] = tf * idf_values[word]\n",
    "\n",
    "# Print the TFIDF matrix in Jupyter notebook\n",
    "print(tfidf_matrix_optimized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6beea04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0cd52e63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'business': {'said': 773, 'us': 393, 'year': 388},\n",
       " 'entertainment': {'film': 519, 'said': 423, 'year': 268},\n",
       " 'politics': {'said': 1059, 'mr': 782, 'would': 531},\n",
       " 'sport': {'said': 452, 'game': 368, 'win': 303},\n",
       " 'tech': {'said': 767, 'use': 476, 'peopl': 431}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating the top 3 most frequent words for each category\n",
    "top_words_frequency = {}\n",
    "\n",
    "for category in sorted(data[\"Category\"].unique()):\n",
    "    # Filtering the data for the current category\n",
    "    category_data = data[data[\"Category\"] == category]\n",
    "    \n",
    "    # Counting word frequencies for the current category\n",
    "    word_frequencies = Counter(word for unigrams in category_data[\"Filtered_Unigrams\"] for word in unigrams)\n",
    "    \n",
    "    # Getting the top 3 most frequent words for each category \n",
    "    top_words = dict(word_frequencies.most_common(3))\n",
    "    \n",
    "    top_words_frequency[category] = top_words\n",
    "\n",
    "top_words_frequency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c500243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'business': {'firm': 0.3008261955203651,\n",
       "  'bank': 0.26751818490824486,\n",
       "  'compani': 0.26191001038677303},\n",
       " 'entertainment': {'film': 0.7194241701450167,\n",
       "  'star': 0.39396079323022454,\n",
       "  'award': 0.39317143948747996},\n",
       " 'politics': {'labour': 0.4567223824204719,\n",
       "  'elect': 0.43448728678902737,\n",
       "  'mr': 0.42492065049653804},\n",
       " 'sport': {'game': 0.3541562034993347,\n",
       "  'england': 0.3133166953690412,\n",
       "  'win': 0.30306092923403677},\n",
       " 'tech': {'mobil': 0.3494922062358214,\n",
       "  'phone': 0.32999603143748346,\n",
       "  'softwar': 0.3190357174296957}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Initialize a dictionary to store the sum of TFIDF values for each word by category\n",
    "tfidf_sums_by_category = {category: {word: 0 for word in dictionary_list} for category in data[\"Category\"].unique()}\n",
    "\n",
    "# Sum up the TFIDF values for each word by category\n",
    "for i, row in data.iterrows():\n",
    "    category = row[\"Category\"]\n",
    "    for j, word in enumerate(dictionary_list):\n",
    "        tfidf_sums_by_category[category][word] += tfidf_matrix_optimized[i][j]\n",
    "\n",
    "# Compute the average TFIDF for each word by category\n",
    "average_tfidf_by_category = {}\n",
    "for category, word_sums in tfidf_sums_by_category.items():\n",
    "    num_docs_in_category = len(data[data[\"Category\"] == category])\n",
    "    average_tfidf_by_category[category] = {word: sum_val / num_docs_in_category for word, sum_val in word_sums.items()}\n",
    "\n",
    "# Extract the top 3 words with the highest average TFIDF for each category\n",
    "top_3_avg_tfidf_by_category = {}\n",
    "for category, word_averages in average_tfidf_by_category.items():\n",
    "    top_3_avg_tfidf_by_category[category] = dict(sorted(word_averages.items(), key=lambda item: item[1], reverse=True)[:3])\n",
    "\n",
    "# Sort the dictionary based on its keys\n",
    "sorted_top_3_avg_tfidf_by_category = dict(sorted(top_3_avg_tfidf_by_category.items()))\n",
    "\n",
    "sorted_top_3_avg_tfidf_by_category\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
